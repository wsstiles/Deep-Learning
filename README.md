# Deep-Learning
A Deep Learning project space in which I explore various methods of constructing neural networks, including Artificial Neural Networks and Convolutional Neural Networks.

## Neural_Networks_Admission_Prediction.ipynb
In this project, I explore feed-forward neural networks to build a model that predicts a student's probability of being accepted into UCLA using **Keras**. In this project, I explore various hyperparameter tunings in an attempt to improve on previous models.

#### Admission_Prediction.csv
This is the dataset used to analyze a student's probability of gaining acceptance into UCLA.

## Street_View_ANN.ipynb
In this project, I create and train an **Artificial Neural Network** model to recognize Google Street View address numbers.

## Street_View_CNN.ipynb
In this project, I create and train a **Convolutional Neural Network** model to recognize Google Street View address numbers.

#### Google Street View Dataset (Available for download for access with Google Colab/Jupyter)
https://drive.google.com/drive/folders/1AuRYnz7hihnEA2EwFCnGXAtwZyXXYucc?usp=sharing


## Fashion_MNIST_ANN.ipynb
In this project, I explore some methods to approach classification problems with an **Artificial Neural Network** model. This ANN is used to classify articles of clothing using the Fashion MNIST dataset from TensorFlow.

## Fashion_MNIST_CNN.ipynb
In this project, I further explore methods to approach classification problems by using a **Convolutional Neural Network** model on the fashion MNIST dataset. This CNN is used to classify articles of clothing using the Fashion MNIST dataset from TensorFlow.


## CIFAR_10_Object_Recognition_CNN.ipynb
In this project, I explore the CIFAR-10 image set from Keras in attempt to build a **Convolutional Neural Network** that can classify images that fall into 10 distinct categories.  After tuning some hyperparameters for the constructed CNN, I go on to explore the technique of **Transfer Learning** by utilizing the VGG16 pre-trained model to attempt to improve on the model.
